# Week 3 Assignment: Neural Network Models for Urban Scene Classification

**Author:** Muhammad Hassan Naeem  
**Course:** Computer Vision - Concordia University  
**Date:** February 1, 2026

## ğŸ“Œ Project Overview

This project implements a **Convolutional Neural Network (CNN)** for classifying urban scenes using the MIT Places dataset. The model uses advanced techniques including **Batch Normalization** and **Dropout** for improved performance and generalization.

## ğŸ¯ Objectives

âœ… Implement a CNN for urban scene classification  
âœ… Use MIT Places dataset (subset focusing on urban environments)  
âœ… Train, evaluate, and optimize the model  
âœ… Visualize results and model performance  
âœ… Complete GitHub integration and documentation

## ğŸ› ï¸ Technologies Used

- **Python 3.8+**
- **PyTorch** - Deep learning framework
- **torchvision** - Computer vision utilities
- **NumPy** - Numerical computations
- **Matplotlib** - Data visualization
- **scikit-learn** - Performance metrics
- **seaborn** - Enhanced visualizations

## ğŸ“ Project Structure

```
Assignment03/Code/
â”‚
â”œâ”€â”€ urban_scene_cnn.py       # Main implementation file
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # Project documentation
â”‚
â”œâ”€â”€ MIT_Places_Urban_Subset/ # Dataset directory (auto-created if missing)
â”‚   â”œâ”€â”€ street/
â”‚   â”œâ”€â”€ highway/
â”‚   â”œâ”€â”€ building/
â”‚   â”œâ”€â”€ park/
â”‚   â””â”€â”€ square/
â”‚
â””â”€â”€ Output Files (generated after running):
    â”œâ”€â”€ sample_images.png         # Sample dataset images
    â”œâ”€â”€ training_history.png      # Training/validation curves
    â”œâ”€â”€ test_accuracy.png         # Final accuracy plot
    â”œâ”€â”€ confusion_matrix.png      # Confusion matrix visualization
    â””â”€â”€ best_model.pth           # Trained model weights
```

## ğŸš€ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/Hassan-Naeem-code/Computer-Vision-Week-03.git
cd Computer-Vision-Week-03
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

Or install manually:

```bash
pip install torch torchvision numpy matplotlib opencv-python scikit-learn seaborn
```

### 3. Dataset Setup

The code will automatically create a dummy dataset if the MIT Places dataset is not found. For real data:

1. Download MIT Places dataset subset
2. Organize into folders by class name
3. Place in `MIT_Places_Urban_Subset/` directory

## ğŸƒ Running the Project

Execute the main script:

```bash
python urban_scene_cnn.py
```

This will:
1. Load and preprocess the dataset
2. Display sample images
3. Initialize the CNN model
4. Train the model for 10 epochs
5. Evaluate on test data
6. Generate visualization plots

## ğŸ§  Model Architecture

### UrbanSceneCNN

The CNN consists of:

**Convolutional Blocks (3):**
- Conv2D â†’ BatchNorm2D â†’ ReLU â†’ MaxPool2D â†’ Dropout2D
- Increasing filters: 32 â†’ 64 â†’ 128

**Fully Connected Layers:**
- Flatten â†’ FC(512) â†’ BatchNorm1D â†’ ReLU â†’ Dropout â†’ FC(num_classes)

**Key Features:**
- Batch Normalization for stable training
- Dropout (0.25 for conv, 0.5 for FC) for regularization
- MaxPooling for spatial dimension reduction
- Total parameters: ~2.5M (varies by num_classes)

## ğŸ“Š Training Configuration

| Hyperparameter | Value |
|----------------|-------|
| Batch Size | 32 |
| Learning Rate | 0.001 |
| Optimizer | Adam |
| Loss Function | CrossEntropyLoss |
| Epochs | 10 |
| Train/Val/Test Split | 70% / 15% / 15% |

## ğŸ“ˆ Results

The model generates the following outputs:

1. **sample_images.png** - Visualization of 6 sample images from dataset
2. **training_history.png** - Loss and accuracy curves over epochs
3. **test_accuracy.png** - Final test set performance
4. **confusion_matrix.png** - Detailed per-class performance
5. **best_model.pth** - Saved model with best validation accuracy

### Expected Performance

With the dummy dataset:
- Training progresses normally
- Model learns to classify synthetic data
- Serves as template for real dataset

With real MIT Places data:
- Expected test accuracy: 70-85% (depends on data quality and size)
- Better performance with more training epochs and data augmentation

## ğŸ”¬ Key Implementation Details

### Data Preprocessing
- Images resized to 128Ã—128
- Normalized using ImageNet statistics
- Random train/val/test split with fixed seed

### Training Features
- Automatic best model saving
- Per-epoch validation
- Training and validation metrics tracking
- GPU support (auto-detects CUDA)

### Evaluation
- Comprehensive test set evaluation
- Confusion matrix generation
- Per-class accuracy analysis

## ğŸ“ Code Highlights

### Batch Normalization
Stabilizes training by normalizing layer inputs:
```python
self.bn1 = nn.BatchNorm2d(32)
```

### Dropout Regularization
Prevents overfitting by randomly dropping connections:
```python
self.dropout1 = nn.Dropout2d(0.25)  # For conv layers
self.dropout4 = nn.Dropout(0.5)     # For FC layers
```

### Data Augmentation (Future Enhancement)
Can add to transforms:
```python
transforms.RandomHorizontalFlip(),
transforms.RandomRotation(10),
transforms.ColorJitter(brightness=0.2, contrast=0.2)
```

## ğŸ¥ Video Walkthrough Topics

When recording your video (5-7 minutes), cover:

1. **Project Overview** (1 min)
   - Explain the goal and dataset
   
2. **Code Walkthrough** (2-3 min)
   - Dataset loading and preprocessing
   - CNN architecture explanation
   - Training loop details
   
3. **Results Analysis** (2 min)
   - Show training curves
   - Discuss test accuracy
   - Analyze confusion matrix
   
4. **Insights & Improvements** (1 min)
   - What worked well
   - Potential improvements
   - Real-world applications

## ğŸš€ Potential Improvements

1. **Data Augmentation** - Add random transforms for better generalization
2. **Learning Rate Scheduling** - Reduce LR when validation plateaus
3. **Deeper Architecture** - Add more convolutional blocks
4. **Transfer Learning** - Use pretrained ResNet/VGG as backbone
5. **Ensemble Methods** - Combine multiple models
6. **Early Stopping** - Stop when validation stops improving

## ğŸ“š References

- [MIT Places Dataset](http://places2.csail.mit.edu/)
- [PyTorch Documentation](https://pytorch.org/docs/)
- [Batch Normalization Paper](https://arxiv.org/abs/1502.03167)
- [Dropout Paper](https://jmlr.org/papers/v15/srivastava14a.html)

## ğŸ“¦ Submission Checklist

âœ… GitHub repository with all code  
âœ… `urban_scene_cnn.py` - Complete implementation  
âœ… `requirements.txt` - All dependencies  
âœ… `README.md` - This documentation  
âœ… Generated visualizations (PNG files)  
âœ… Video walkthrough (5-7 minutes)  
âœ… PowerPoint presentation (6-7 slides)  
âœ… ZIP file of repository  

## ğŸ¤ GitHub Integration

### Initial Setup
```bash
git init
git add .
git commit -m "Initial commit: Urban Scene CNN"
git remote add origin https://github.com/Hassan-Naeem-code/Computer-Vision-Week-03.git
git push -u origin main
```

### Subsequent Updates
```bash
git add .
git commit -m "Your commit message here"
git push
```

## ğŸ“§ Contact

**Muhammad Hassan Naeem**  
Concordia University  
Computer Vision Course  

---

## ğŸ‰ Conclusion

This project demonstrates the implementation of a CNN for urban scene classification, incorporating modern deep learning techniques like batch normalization and dropout. The modular code structure makes it easy to experiment with different architectures and hyperparameters.

**Ready for submission!** ğŸš€

---

*Last Updated: February 1, 2026*
